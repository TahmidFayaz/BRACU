# -*- coding: utf-8 -*-
"""Employee Attrition Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ukqvlDOyBhgD5h5xU7e2j6nk9GvH2IUE
"""

import pandas as pd
import numpy as np
import math
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, f1_score
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from imblearn.over_sampling import SMOTE

#Loading Dataset
path="/content/drive/MyDrive/Dataset/employee attriation dataset.csv"
df=pd.read_csv(path)
df.head(5)

"""# **EDA**

#Data Analysis
"""

df

df.head(20)

df.tail(20)

df.shape

#Datatypes
df.info()

"""##Data Spliting"""

##Selecting numerical features
numerical_data = df.select_dtypes(include='number')

#append the features of numerical_data to list
numerical_features=numerical_data.columns.tolist()

print(f'There are {len(numerical_features)} numerical features:')
print("\n")
print(numerical_features)

#Selecting categoricalfeatures
categorical_data=df.select_dtypes(include= 'object')

#append the features of categorical_data to list
categorical_features=categorical_data.columns.tolist()

print(f'There are {len(categorical_features)} categorical features:')
print("\n")

print(categorical_features)

numerical_data.describe().T

categorical_data.describe().T

"""#Numerical Features"""

numerical_data.var()       # Variance of each numerical features

numerical_data.skew()

"""Histrograms"""

numerical_data.hist(figsize=(16,12),bins=20)
plt.subplots_adjust(hspace=0.5, wspace=0.4)
plt.show()

"""Boxplots"""

import matplotlib.pyplot as plt
import seaborn as sns

# Select only numerical columns for boxplot analysis
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

n_cols = 2
n_rows = math.ceil(len(numeric_cols) / n_cols)


# Set up the figure
plt.figure(figsize=(16, n_rows * 4))

# Plot boxplots for each numerical feature including the target variable 'OUTCOME'
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(len(numeric_cols), 1, i)
    sns.boxplot(x=df[col], color='brown')
    plt.title(f'Boxplot of {col}', fontsize=12)
    plt.tight_layout()

plt.show()

numerical_data.nunique()

numerical_data.isnull().sum()

"""#Categorical Features"""

unique_counts=categorical_data.nunique()         # unique values counts
print(unique_counts)

for col in categorical_features:
    plt.title(f'Distribution of {col}')
    categorical_data[col].value_counts().sort_index().plot(kind='bar', rot=90, xlabel=col,ylabel='count', color='brown')
    plt.show()

"""#Correlation Analysis"""

correlation_matrix = numerical_data.corr()      # Calculate the correlation matrix
correlation_matrix

plt.figure(figsize=(14, 12))     # Plotting the heatmap for correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap='YlOrBr', fmt='.2f', linewidths=0.3)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Select numerical columns for correlation
numerical_data = df.select_dtypes(include=['int64', 'float64'])

# Correlation using different methods
corr1 = numerical_data.corr('pearson')[['Attrition']].sort_values(by='Attrition', ascending=False)
corr2 = numerical_data.corr('spearman')[['Attrition']].sort_values(by='Attrition', ascending=False)
corr3 = numerical_data.corr('kendall')[['Attrition']].sort_values(by='Attrition', ascending=False)

# Plotting the correlations using different methods
fig, ax = plt.subplots(3, 1, figsize=(10, 14))

# Setting titles for each plot
ax[0].set_title('Pearson Method')
ax[1].set_title('Spearman Method')
ax[2].set_title('Kendall Method')

# Generating heatmaps for each method
sns.heatmap(corr1, ax=ax[0], annot=True)
sns.heatmap(corr2, ax=ax[1], annot=True)
sns.heatmap(corr3, ax=ax[2], annot=True)

# Adjust layout for better visualization
plt.tight_layout()
plt.show()

# Group instances based on the 'Attrition' variable
class_counts = df.groupby("Attrition").size()

# Define columns and outcome variable
columns = ['attrition', 'count', 'percentage']
outcome = [0, 1]
count = list()
percentage = list()

# Calculate the percentage of each class of the 'Attrition' variable
total_records = len(df)  # Total number of records
for val in range(2):
    count.append(class_counts[val])
    percent = (class_counts[val] / total_records) * 100
    percentage.append(percent)

# Convert the calculated values into a DataFrame
imbalance_df = pd.DataFrame(list(zip(outcome, count, percentage)), columns=columns)

# Display the imbalance DataFrame
imbalance_df

sns.barplot(data=imbalance_df,x=imbalance_df['attrition'],y=imbalance_df['percentage'], color='Black')
plt.show()

# Count numerical columns
nplots = numerical_data.shape[1]

# Compute rows and cols (e.g. 5 columns per row)
ncols = 5
nrows = math.ceil(nplots / ncols)

# Plot density plots
numerical_data.plot(
    kind='density',
    figsize=(20, nrows*3),   # scale height with rows
    subplots=True,
    layout=(nrows, ncols),
    sharex=False,
    title="Density Plot of Numerical Features"
)

plt.tight_layout()
plt.show()

"""##**PRE-PROCESSING**"""

print('Pre processed df shape:', df.shape)

print(df.isnull().sum())

df.drop(['id', 'EmployeeCount', 'StandardHours', 'Over18'], axis=1, inplace=True)

df

# Assuming 'df' is your DataFrame
encoder = OrdinalEncoder()

# Select columns with object datatype (typically strings)
cat_cols = df.select_dtypes(include=['object']).columns.to_list()

# Apply the encoder to the categorical columns of the single dataframe
df[cat_cols] = encoder.fit_transform(df[cat_cols])

df

df.head(10)

X = df.drop('Attrition', axis=1)  # Features (all columns except 'Attrition')
y = df['Attrition']  # Target (Attrition column)

# Split the data into training and testing sets (30% test size)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=44)

smote = SMOTE(random_state = 44)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_resampled)
X_test_scaled = scaler.transform(X_test)

"""##**Models**

**Neural Networks**
"""

df.shape

# Define the Keras model
nn_model = Sequential([
    Dense(256, activation='relu', input_dim=X_train_scaled.shape[1]),  # Input layer with 256 neurons
    Dense(128, activation='relu'), # Hidden layer with 128 neurons
    Dense(64, activation='relu'), # Hidden layer with 64 neurons
    Dense(1, activation='sigmoid')  # Output layer with 1 neuron (sigmoid for binary classification)
])

# Compile the model
nn_model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',  # Binary classification loss
              metrics=['accuracy'])

history = nn_model.fit(X_train_scaled, y_resampled,

                    epochs=100,  # Number of epochs
                    batch_size=64,  # Batch size
                    # class_weight=class_weight_dict
                    )

y_pred_nn = (nn_model.predict(X_test_scaled) > 0.5).astype(int)
y_probs_nn = nn_model.predict(X_test_scaled)

"""**Logistic Regression**"""

log_reg_model = LogisticRegression()
log_reg_model.fit(X_train_scaled, y_resampled)
y_pred_log = log_reg_model.predict(X_test_scaled)
y_probs_log = log_reg_model.predict_proba(X_test_scaled)[:, 1]

"""**Decision Tree**"""

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train_scaled, y_resampled)
y_pred_dt = dt_model.predict(X_test_scaled)
y_probs_dt = dt_model.predict_proba(X_test_scaled)[:, 1]

"""##**EVALUATION**"""

# ROC and AUC
nn_fpr, nn_tpr, nn_ = roc_curve(y_test, y_probs_nn)
nn_roc_auc = auc(nn_fpr, nn_tpr)

log_fpr, log_tpr, log_ = roc_curve(y_test, y_probs_log)
log_roc_auc = auc(log_fpr, log_tpr)

dt_fpr, dt_tpr, dt_ = roc_curve(y_test, y_probs_dt)
dt_roc_auc = auc(dt_fpr, dt_tpr)

# Plot the ROC curve
plt.plot(nn_fpr, nn_tpr, label=f"Nueral Network (AUC = {nn_roc_auc:.2f})")
plt.plot(log_fpr, log_tpr, label=f"Logistic Regression (AUC = {log_roc_auc:.2f})")
plt.plot(dt_fpr, dt_tpr, label=f"Decision Tree (AUC = {dt_roc_auc:.2f})")

# Plot random guess line (diagonal)
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison - Attrition Prediction")
plt.legend(loc="lower right")
plt.grid()
plt.show()

# --- Logistic Regression ---
cm_log = confusion_matrix(y_test, y_pred_log, labels=[0, 1])
ConfusionMatrixDisplay(cm_log, display_labels=['No Attrition', 'Attrition']).plot(cmap="Blues")
plt.title("Logistic Regression — Confusion Matrix")
plt.show()

# --- Neural Network ---
cm_nn = confusion_matrix(y_test, y_pred_nn, labels=[0, 1])
ConfusionMatrixDisplay(cm_nn, display_labels=['No Attrition', 'Attrition']).plot(cmap="Oranges")
plt.title("Neural Network — Confusion Matrix")
plt.show()

# --- Decision Tree ---
cm_dt = confusion_matrix(y_test, y_pred_dt, labels=[0, 1])
ConfusionMatrixDisplay(cm_dt, display_labels=['No Attrition', 'Attrition']).plot(cmap="Greens")
plt.title("Decision Tree — Confusion Matrix")
plt.show()

print("Neural Network Accuracy:", accuracy_score(y_test, y_pred_nn))
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))

"""**NEURAL NETWORK LOSS CURVE**"""

# Plot loss curve
plt.plot(history.history['loss'])
plt.title("Neural network Loss Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

#Print test error
print(f"Testing Accuracy: {round(nn_model.evaluate(X_test_scaled, y_test)[1] * 100, 2)}%")

print("Logistic Regression :")
print(classification_report(y_test, y_pred_log, target_names=["0", "1"]))

print("Neural Network :")
print(classification_report(y_test, y_pred_nn, target_names=["0", "1"]))

print("Decision Tree:")
print(classification_report(y_test, y_pred_dt, target_names=["0", "1"]))

# Accuracy and F1 scores
accuracy_nn = accuracy_score(y_test, y_pred_nn)
accuracy_log = accuracy_score(y_test, y_pred_log)
accuracy_dt = accuracy_score(y_test, y_pred_dt)

f1_nn = f1_score(y_test, y_pred_nn, average='weighted')
f1_log = f1_score(y_test, y_pred_log, average='weighted')
f1_dt = f1_score(y_test, y_pred_dt, average='weighted')

# Bar chart data
models = ['Logistic Regression', 'Neural Network', 'Decision Tree']
accuracy_scores = [accuracy_log, accuracy_nn, accuracy_dt]
f1_scores = [f1_log, f1_nn, f1_dt]

x = np.arange(len(models))
width = 0.30

plt.figure(figsize=(10, 6))
plt.bar(x - width/2, accuracy_scores, width, label='Accuracy', color='#253564')
plt.bar(x + width/2, f1_scores, width, label='F1 Score', color='#8AAFF9')

plt.xlabel('Models')
plt.ylabel('Scores')
plt.title('Prediction Accuracy and F1 Score Comparison')
plt.xticks(x, models)

plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')
plt.tight_layout()

plt.show()